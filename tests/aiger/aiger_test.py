"""CSV dataset writer test"""

from ml2.aiger import AIGERCircuit, AIGERToSeqTokenizer
from ml2.tokenizers.vocabulary import Vocabulary


def test_aiger_circuit_from_str_without_header_1():
    circuit_str = "2\n4\n6\n8\n10\n17 11 15\n10 11\n0\n0\n1\n0\n16"
    circuit = AIGERCircuit.from_str_without_header(
        circuit=circuit_str,
        num_inputs=5,
        num_outputs=5,
        components=["header", "inputs", "ands", "latches", "outputs"],
    )
    assert circuit.to_str() == "aag 8 5 1 5 1\n2\n4\n6\n8\n10\n10 11\n0\n0\n1\n0\n16\n17 11 15"


def test_aiger_circuit_from_str_without_header_2():
    circuit_str = "2\n4\n6\n8\n10\n12 7\n0\n0\n1\n0\n16\n14 9 6\n16 14 12\ni0 i0\ni1 i1\ni2 i2\ni3 i3\ni4 i4\nl0 l0\no0 o0\no1 o1\no2 o2\no3 o3\no4 o4"
    circuit = AIGERCircuit.from_str_without_header(
        circuit=circuit_str, num_inputs=5, num_outputs=5
    )
    assert (
        circuit.to_str()
        == "aag 8 5 1 5 2\n2\n4\n6\n8\n10\n12 7\n0\n0\n1\n0\n16\n14 9 6\n16 14 12\ni0 i0\ni1 i1\ni2 i2\ni3 i3\ni4 i4\nl0 l0\no0 o0\no1 o1\no2 o2\no3 o3\no4 o4"
    )


def test_aiger_circuit_from_csv_fields():
    d = {
        "circuit": "aag 9 5 1 5 3\\n2\\n4\\n6\\n8\\n10\\n12 18\\n1\\n1\\n1\\n0\\n16\\n14 13 5\\n16 15 6\\n18 15 7\\ni0 i0\\ni1 i1\\ni2 i2\\ni3 i3\\ni4 i4\\nl0 l0\\no0 o0\\no1 o1\\no2 o2\\no3 o3\\no4 o4"
    }
    circuit = AIGERCircuit.from_csv_fields(d)
    assert circuit.header.max_var_id == 9
    assert circuit.num_ands == 3
    d_n = circuit.to_csv_fields()
    assert all(d_n[k] == v for k, v in d.items())


def test_tokenizer():
    token_to_id = {
        "<p>": 0,
        "0": 1,
        "1": 2,
        "2": 3,
        "3": 4,
        "4": 5,
        "5": 6,
        "6": 7,
        "7": 8,
        "8": 9,
        "9": 10,
        "10": 11,
        "11": 12,
        "12": 13,
        "13": 14,
        "14": 15,
        "15": 16,
        "16": 17,
        "17": 18,
        "18": 19,
        "19": 20,
        "20": 21,
        "21": 22,
        "22": 23,
        "23": 24,
        "24": 25,
        "25": 26,
        "26": 27,
        "27": 28,
        "28": 29,
        "29": 30,
        "30": 31,
        "31": 32,
        "32": 33,
        "33": 34,
        "34": 35,
        "35": 36,
        "36": 37,
        "37": 38,
        "38": 39,
        "39": 40,
        "40": 41,
        "<s>": 42,
        "<e>": 43,
        "<c>": 44,
        "<l>": 45,
        "<n>": 46,
        "<r>": 47,
        "<u>": 48,
    }
    vocab = Vocabulary(token_to_id)
    tokenizer = AIGERToSeqTokenizer(
        start=True,
        eos=True,
        pad=128,
        components=["header", "inputs", "latches", "outputs", "ands"],
        inputs=["i0", "i1", "i2", "i3", "i4"],
        outputs=["o0", "o1", "o2", "o3", "o4"],
        unfold_negations=False,
        unfold_latches=False,
        vocabulary=vocab,
    )
    circuit = AIGERCircuit.from_str(
        "aag 19 5 3 5 11\n2\n4\n6\n8\n10\n12 30\n14 35\n16 39\n26\n0\n0\n0\n0\n18 17 9\n20 13 5\n22 20 15\n24 23 13\n26 24 19\n28 19 14\n30 28 20\n32 16 14\n34 33 25\n36 19 13\n38 37 33\ni0 i0\ni1 i1\ni2 i2\ni3 i3\ni4 i4\nl0 l0\nl1 l1\nl2 l2\no0 o0\no1 o1\no2 o2\no3 o3\no4 o4"
    )
    encoding = tokenizer.encode(circuit)
    # Test token_to_id
    assert encoding.tokens == [
        "19",
        "5",
        "3",
        "5",
        "11",
        "<n>",
        "2",
        "<n>",
        "4",
        "<n>",
        "6",
        "<n>",
        "8",
        "<n>",
        "10",
        "<n>",
        "12",
        "30",
        "<n>",
        "14",
        "35",
        "<n>",
        "16",
        "39",
        "<n>",
        "26",
        "<n>",
        "0",
        "<n>",
        "0",
        "<n>",
        "0",
        "<n>",
        "0",
        "<n>",
        "18",
        "17",
        "9",
        "<n>",
        "20",
        "13",
        "5",
        "<n>",
        "22",
        "20",
        "15",
        "<n>",
        "24",
        "23",
        "13",
        "<n>",
        "26",
        "24",
        "19",
        "<n>",
        "28",
        "19",
        "14",
        "<n>",
        "30",
        "28",
        "20",
        "<n>",
        "32",
        "16",
        "14",
        "<n>",
        "34",
        "33",
        "25",
        "<n>",
        "36",
        "19",
        "13",
        "<n>",
        "38",
        "37",
        "33",
    ]
    assert encoding.ids == [
        42,
        20,
        6,
        4,
        6,
        12,
        46,
        3,
        46,
        5,
        46,
        7,
        46,
        9,
        46,
        11,
        46,
        13,
        31,
        46,
        15,
        36,
        46,
        17,
        40,
        46,
        27,
        46,
        1,
        46,
        1,
        46,
        1,
        46,
        1,
        46,
        19,
        18,
        10,
        46,
        21,
        14,
        6,
        46,
        23,
        21,
        16,
        46,
        25,
        24,
        14,
        46,
        27,
        25,
        20,
        46,
        29,
        20,
        15,
        46,
        31,
        29,
        21,
        46,
        33,
        17,
        15,
        46,
        35,
        34,
        26,
        46,
        37,
        20,
        14,
        46,
        39,
        38,
        34,
        43,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
        0,
    ]
