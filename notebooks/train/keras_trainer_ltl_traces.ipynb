{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LTL Trace Generation with TensorFlow Transformer and Keras Transformer Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from ml2.datasets import CSVDataset, SplitDataset\n",
        "from ml2.ltl import LTLFormula\n",
        "from ml2.tokenizers import ExprToSeqTokenizer\n",
        "from ml2.trace import SymbolicTrace, SymTraceToSeqTokenizer\n",
        "from ml2.train import KerasTransformerTrainer\n",
        "from ml2.pipelines import TFTransformerPipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Input Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_tokenizer = ExprToSeqTokenizer(dtype=LTLFormula, pad=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "formula_data = CSVDataset.load(\"rft-0/val\", \"ltl-strace\", dtype=LTLFormula)\n",
        "input_tokenizer.build_vocabulary(formula_data.generator())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Target Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_tokenizer = SymTraceToSeqTokenizer(notation=\"infix\", eos=True, pad=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_data = CSVDataset.load(\"rft-0/val\", \"ltl-strace\", dtype=SymbolicTrace)\n",
        "target_tokenizer.build_vocabulary(target_data.generator(), add_start=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_config = {\n",
        "    \"alpha\": 0.5,\n",
        "    \"beam_size\": 2,\n",
        "    \"custom_pos_enc\": True,\n",
        "    \"d_embed_dec\": 128,\n",
        "    \"d_embed_enc\": 128,\n",
        "    \"d_ff\": 512,\n",
        "    \"dropout\": 0.0,\n",
        "    \"dtype_float\": tf.float32,\n",
        "    \"dtype_int\": tf.int32,\n",
        "    \"ff_activation\": \"relu\",\n",
        "    \"num_heads\": 4,\n",
        "    \"num_layers_dec\": 4,\n",
        "    \"num_layers_enc\": 4,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = TFTransformerPipeline(\n",
        "    name=\"t-0\",\n",
        "    project=\"ltl-strace\",\n",
        "    model_config=model_config,\n",
        "    input_tokenizer=input_tokenizer,\n",
        "    target_tokenizer=target_tokenizer,\n",
        "    max_input_length=128,\n",
        "    max_target_length=64,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = SplitDataset.load(\"rft-0\", \"ltl-strace\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = KerasTransformerTrainer(\n",
        "    pipeline=pipeline,\n",
        "    train_dataset=data[\"train\"],\n",
        "    val_dataset=data[\"val\"],\n",
        "    steps=500,\n",
        "    val_freq=500,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "formula = LTLFormula.from_str(\"! X ( a & 1 U b )\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = pipeline(formula)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for pred in preds:\n",
        "    if pred is None:\n",
        "        print('Decoding Error')\n",
        "    else:\n",
        "        print(pred.to_str())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pipeline.eval_attn_weights(formula)"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "02a3c6c9a3f7fd199765eef1a13fc7f40868927109d86265acbef8b3053d7df3"
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('ml2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
